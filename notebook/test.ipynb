{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0036ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_core.models import UserMessage, ModelFamily\n",
    "\n",
    "ollama_client = OllamaChatCompletionClient(\n",
    "    model=\"qwen2.5:7b-instruct\",\n",
    "    model_info = {\n",
    "        'vision': False,\n",
    "        'function_calling': True,\n",
    "        'json_output': True,\n",
    "        'family': ModelFamily.GPT_4O\n",
    "    },\n",
    "    options={\n",
    "        'num_ctx': 6000,}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a507a1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "读取本地文件 c1.txt 的内容并总结。\n",
      "---------- TextMessage (MagenticOneOrchestrator) ----------\n",
      "\n",
      "We are working to address the following user request:\n",
      "\n",
      "读取本地文件 c1.txt 的内容并总结。\n",
      "\n",
      "\n",
      "To answer this request we have assembled the following team:\n",
      "\n",
      "FileSurferAgent: An agent that can handle local files.\n",
      "\n",
      "\n",
      "Here is an initial fact sheet to consider:\n",
      "\n",
      "1. GIVEN OR VERIFIED FACTS\n",
      "   - The request asks to read the content of a local file named \"c1.txt\".\n",
      "   \n",
      "2. FACTS TO LOOK UP\n",
      "   - There are no specific facts or figures given in the request that need to be looked up.\n",
      "\n",
      "3. FACTS TO DERIVE\n",
      "   - No logical deductions, simulations, or computations are required based on the provided information.\n",
      "\n",
      "4. EDUCATED GUESSES\n",
      "   - None of the information provided allows for any educated guesses.\n",
      "\n",
      "\n",
      "Here is the plan to follow as best as possible:\n",
      "\n",
      "- FileSurferAgent: Read the content of the local file \"c1.txt\".\n",
      "- Summarize the content read from the file \"c1.txt\".\n",
      "\n",
      "---------- TextMessage (MagenticOneOrchestrator) ----------\n",
      "请读取本地文件 c1.txt 的内容并总结。\n",
      "---------- TextMessage (FileSurferAgent) ----------\n",
      "Path: /home/userroot/dev/shallow_edu/course/docs/c1.txt\n",
      "Viewport position: Showing page 1 of 3.\n",
      "=======================\n",
      "提示词工程 (Prompt Engineering) 最佳实践\n",
      "AI原生应用开发/实践案例\n",
      "\n",
      "免费大模型课程\n",
      "LLM\n",
      "Prompt\n",
      "2024.06.26\n",
      "28550看过\n",
      "全面的专业 Prompt Engineering 入门宝典\n",
      "复制\n",
      "正文\n",
      "\n",
      "AI\n",
      "智能创作\n",
      "通用\n",
      "图片\n",
      "表格\n",
      "附件\n",
      "代码块\n",
      "公式\n",
      "超链接\n",
      "提及\n",
      "阅读统计\n",
      "高亮信息\n",
      "流程图\n",
      "思维导图\n",
      "文本格式\n",
      "正文\n",
      "一级标题\n",
      "二级标题\n",
      "三级标题\n",
      "四级标题\n",
      "五级标题\n",
      "六级标题\n",
      "无序列表\n",
      "有序列表\n",
      "待办列表\n",
      "引用\n",
      "分割线\n",
      "数据表\n",
      "表格视图\n",
      "相册视图\n",
      "看板视图\n",
      "甘特视图\n",
      "日历视图\n",
      "架构视图\n",
      "第三方应用\n",
      "DuChat\n",
      "Beta\n",
      "百度地图\n",
      "CodePen\n",
      "Figma\n",
      "Prompt Engineering 概念解析\n",
      "提示工程是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型（Large Language Model, LLM）用于各场景和研究领域。研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。\n",
      "例如，在openai官方提供的大模型中，text-davinci-003和davinci是最常用的两个模型。text-davinci-003是经过大量指令微(教)调(化)过的模型，而davinci则是Foundation模型没有经过“教化”。\n",
      "对于经过教化的text-davinci-003模型，想要发挥其能力需要进行适当的prompt engineering来做引导。\n",
      "而对于没有教化过的davinci模型，我们要把人为书写Prompt对其进行教化，即指令微调。虽然davinci模型本身通过Prompt Engineering可以激发其大量的底层能力，但通常由于准确度不够高而不具备实用性。\n",
      "我们日常说的Prompt Engineering更是指如何激发一个被调教过的模型（举例，text-davinci-003、文心一言、chatglm等）所具备的成熟能力，更好的服务我们自己。\n",
      "最简单的Prompt举例\n",
      "备注：除非特别说明，本指南默认所有示例都是基于 OpenAI 的大语言模型 ﻿﻿text-davinci-003﻿﻿ 进行测试，并且使用该模型的默认配置，如 ﻿﻿temperature=0.7﻿﻿ 和 ﻿﻿top_p=1﻿﻿ 等。\n",
      "Temperature：简单来说，﻿﻿temperature﻿﻿ 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。我们目前也在增加其他可能 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 temperature 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，你可以适当调高 ﻿﻿temperature﻿﻿ 参数值。\n",
      "Top_p：同样，使用 ﻿﻿top_p﻿﻿（与 ﻿﻿temperature﻿﻿ 一起称为核采样的技术），可以用来控制模型返回结果的真实性。如果你需要准确和事实的答案，就把参数值调低。如果你想要更多样化的答案，就把参数值调高一些。\n",
      "﻿\n",
      "需要Prompt Engineering 的场景\n",
      "总结来说，需要进行Prompt Engineering的主要场景有如下两种：\n",
      "对于不可被训练的GPT3.5+类的模型，想要获得更好的任务效果一般需要Prompt Engineering。其中，对于GPT3.5+类模型已有能力的探索相对简单，通过评估不同的Prompt效果即可。对于GPT3.5+类模型不太具备的能力，需要通过探索GPT3 Base模型能力的任务来说，还需要构造一些具备代表意义的Example，通过不断调整Prompt中的Task Description、Context、Examples来获得最优的效果，此场景下Prompt Engineering成本相对高。\n",
      "对于可Instruction Tuning的模型来说，构造Prompt的成本相对较低，大部分成本转嫁给标注成本，通过在设计好的Prompt中调优任务的效果即可，不需要特殊的Prompt Enigineering。\n",
      "﻿\n",
      "﻿\n",
      "\n",
      "﻿\n",
      "注意：上图没有列出GPT3类模型需要进行Prompt Engineering的场景，原因是被GPT3.5进行Prompt Engineering的场景覆盖了。此外，在实际使用中，预置模型最好都是GPT3.5+类模型，具备一定优势能力后再进行实际应用。\n",
      "Prompt Engineering 的方法\n",
      "Prompt 的标准结构\n",
      "整个Prompt可以看做是一个函数  模型输出 = F(用户输入)，而F本身就包括任务描述、上下文、示例等等，“Prompt Design工程师”主要的工作就是设计这个F。\n",
      "﻿\n",
      "﻿\n",
      "\n",
      "﻿\n",
      "示例\n",
      "Prompt Engineering 的典型技术\n",
      "零样本提示词\n",
      "﻿\n",
      "少样本提示词\n",
      "思维链提示法\n",
      "零样本思维链提示法\n",
      "设计全局性的System信息\n",
      "﻿\n",
      "﻿\n",
      "\n",
      "﻿\n",
      "Prompt Engineering 典型应用\n",
      "生成数据\n",
      "利用Prompt+真实数据，从InstructGPT模型中找到答案，作为训练数据或评估数据使用。举例子：从一篇文档中挖掘问答对、基于给定的实体生成相关的属性信息等。\n",
      "构造副驾驶\n",
      "Prompt Engineering 的效果检验\n",
      "表述方式的评估：Prompt中的描述应该确保明确、准确、有结构性、简单易懂、不能有错别字和语法错误、不能有死链接\n",
      "人工评估：对 Prompt + Completion 进行结果正确性的人工 review ，按照准确率来评估。\n",
      "与 Text-Davinci-003 对比：通过对比 GSB 衡量与 GPT3.5 模型的效果对比。\n",
      "Prompt质量评估自动化方法：计算人工设计的 Prompt 在 GPT3.5+ 模型上的 PPL (PPL, Perplexity, 即困惑度，是用来度量一个概率分布或概率模型预测样本的好坏程度的指标)。\n",
      "可能的问题\n",
      "Prompt越长性能越差：因为当前模型采用Transformer架构，计算复杂度有O(L^2)，L为文本序列token个数，因此Prompt越长性能越差。同时，Prompt越长，模型单次解码可生成的文本长度越短。解决方案：如果Prompt过长导致预测性能不符合预期，采用instruction tuning在效果和成本方面都更有优势。\n",
      "缩短Prompt的进阶方法：对于一些Prompt，例如阅读理解任务，需要在Prompt中加入外部的文本形成完成的Prompt，这种情形下通常难以缩短Prompt。一种可行的方法是把外部文本当成预训练文本语料学习到模型里，让模型记忆其中的一部分知识，再通过Prompt设计直接进行context-free的问答。\n",
      "对于确定场景：用户需要输入较多Prompt描述才能正确获得结果，使用体验会明显下降。解决方案：尽量开放以【用户输入】为参数的API直接给用户使用，而不是输入整个Prompt，将Prompt固化到API中，可以保持效果稳定和更新的灵活性。\n",
      "Prompt 题库与示例\n",
      "根据BIG-BENCH对任务类别梳理，挑选四大类任务重点关注，分别是自然语言理解、科学知识、世界知识（通识）、职业角色扮演\n",
      "理解类\n",
      "学科知识\n",
      "世界知识（通识）\n",
      "职业角色扮演\n",
      "﻿\n",
      "编号\n",
      "任务\n",
      "Prompt示例\n",
      "1\n",
      "语言检测器\n",
      "我希望你充当语言检测器。我会用任何语言输入一个句子，你会回答我，我写的句子在你是用哪种语言写的。不要写任何解释或其他文字，只需回复语言名称即可。我的第一句话是“Kiel vi fartas？Kiel iras via tago？”\n",
      "2\n",
      "充当英语翻译和改进者\n",
      "我想让你充当英语翻译员、拼写纠正员和改进员。我会用任何语言与你交谈，你会检测语言，翻译它并用我的文本的更正和改进版本用英语回答。我希望你用更优美优雅的高级英语单词和句子替换我简化的 A0 级单词和句子。保持相同的意思，但使它们更文艺。我要你只回复更正、改进，不要写任何解释。我的第一句话是“istanbulu cok seviyom burada olmak cok guzel”\n",
      "3\n",
      "充当英英词典(附中文解释)\n",
      "我想让你充当英英词典，对于给出的英文单词，你要给出其中文意思以及英文解释，并且给出一个例句，此外不要有其他反馈，第一个单词是“Hello\"\n",
      "4\n",
      "担任面试官\n",
      "我想让你担任Android开发工程师面试官。我将成为候选人，您将向我询问Android开发工程师职位的面试问题。我希望你只作为面试官回答。不要一次写出所有的问题。我希望你只对我进行采访。问我问题，等待我的回答。不要写解释。像面试官一样一个一个问我，等我回答。我的第一句话是“面试官你好”\n",
      "5\n",
      "充当旅游指南\n",
      "我想让你做一个旅游指南。我会把我的位置写给你，你会推荐一个靠近我的位置的地方。在某些情况下，我还会告诉您我将访问的地方类型。您还会向我推荐靠近我的第一个位置的类似类型的地方。我的第一个建议请求是“我在上海，我只想参观博物馆。”\n",
      "6\n",
      "充当抄袭检查员\n",
      "我想让你充当剽窃检查员。我会给你写句子，你只会用给定句子的语言在抄袭检查中未被发现的情况下回复，别无其他。不要在回复上写解释。我的第一句话是“为了让计算机像人类一样行动，语音识别系统必须能够处理非语言信息，例如说话者的情绪状态。”\n",
      "7\n",
      "充当“电影/书籍/任何东西”中的“角色”\n",
      "我希望你表现得像{series} 中的{Character}。我希望你像{Character}一样回应和回答。不要写任何解释。只回答像{character}。你必须知道{character}的所有知识。我的第一句话是“你好”\n",
      "8\n",
      "作为广告商\n",
      "我想让你充当广告商。您将创建一个活动来推广您选择的产品或服务。您将选择目标受众，制定关键信息和口号，选择宣传媒体渠道，并决定实现目标所需的任何其他活动。我的第一个建议请求是“我需要帮助针对 18-30 岁的年轻人制作一种新型能量饮料的广告活动。”\n",
      "9\n",
      "充当讲故事的人\n",
      "我想让你扮演讲故事的角色。您将想出引人入胜、富有想象力和吸引观众的有趣故事。它可以是童话故事、教育故事或任何其他类型的故事，有可能吸引人们的注意力和想象力。根据目标受众，您可以为讲故事环节选择特定的主题或主题，例如，如果是儿童，则可以谈论动物；如果是成年人，那么基于历史的故事可能会更好地吸引他们等等。我的第一个要求是“我需要一个关于毅力的有趣故事。”\n",
      "10\n",
      "担任足球解说员\n",
      "我想让你担任足球评论员。我会给你描述正在进行的足球比赛，你会评论比赛，分析到目前为止发生的事情，并预测比赛可能会如何结束。您应该了解足球术语、战术、每场比赛涉及的球员/球队，并主要专注于提供明智的评论，而不仅仅是逐场叙述。我的第一个请求是“我正在观看曼联对切尔西的比赛——为这场比赛提供评论。”\n",
      "11\n",
      "扮演脱口秀喜剧演员\n",
      "我想让你扮演一个脱口秀喜剧演员。我将为您提供一些与时事相关的话题，您将运用您的智慧、创造力和观察能力，根据这些话题创建一个例程。您还应该确保将个人轶事或经历融入日常活动中，以使其对观众更具相关性和吸引力。我的第一个请求是“我想要幽默地看待政治”。\n",
      "12\n",
      "充当励志教练\n",
      "我希望你充当激励教练。我将为您提供一些关于某人的目标和挑战的信息，而您的工作就是想出可以帮助此人实现目标的策略。这可能涉及提供积极的肯定、提供有用的建议或建议他们可以采取哪些行动来实现最终目标。我的第一个请求是“我需要帮助来激励自己在为即将到来的考试学习时保持纪律”。\n",
      "13\n",
      "担任辩手\n",
      "我要你扮演辩手。我会为你提供一些与时事相关的话题，你的任务是研究辩论的双方，为每一方提出有效的论据，驳斥对立的观点，并根据证据得出有说服力的结论。你的目标是帮助人们从讨论中解脱出来，增加对手头主题的知识和洞察力。我的第一个请求是“我想要一篇关于 Deno 的评论文章。”\n",
      "14\n",
      "担任职业顾问\n",
      "我想让你担任职业顾问。我将为您提供一个在职业生涯中寻求指导的人，您的任务是帮助他们根据自己的技能、兴趣和经验确定最适合的职业。您还应该对可用的各种选项进行研究，解释不同行业的就业市场趋势，并就哪些资格对追求特定领域有益提出建议。我的第一个请求是“我想建议那些想在软件工程领域从事潜在职业的人。”\n",
      "\n",
      "---------- TextMessage (MagenticOneOrchestrator) ----------\n",
      "根据文件 \"c1.txt\" 的内容，这是一篇关于提示词工程（Prompt Engineering）最佳实践的总结。文章首先介绍了提示词工程的概念及其在提升大语言模型处理复杂任务场景能力中的作用，特别是对于经过微调的如 text-davinci-003 模型而言。它还详细讨论了需要进行提示词工程的主要场景、方法以及典型应用。这些应用包括生成数据、构造副驾驶、增强表述方式等，并列举了一些具体的Prompt示例来帮助理解如何在实际任务中使用提示词工程。\n",
      "\n",
      "总结来看，提示词工程是通过精心设计和优化提示词来充分利用大语言模型的能力的一种技术。它对于提升特定任务的效果至关重要，并且适用于多种场景，从简单的零样本或少样本提示词到复杂的对话模拟等。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='读取本地文件 c1.txt 的内容并总结。', type='TextMessage'), TextMessage(source='MagenticOneOrchestrator', models_usage=None, metadata={}, content='\\nWe are working to address the following user request:\\n\\n读取本地文件 c1.txt 的内容并总结。\\n\\n\\nTo answer this request we have assembled the following team:\\n\\nFileSurferAgent: An agent that can handle local files.\\n\\n\\nHere is an initial fact sheet to consider:\\n\\n1. GIVEN OR VERIFIED FACTS\\n   - The request asks to read the content of a local file named \"c1.txt\".\\n   \\n2. FACTS TO LOOK UP\\n   - There are no specific facts or figures given in the request that need to be looked up.\\n\\n3. FACTS TO DERIVE\\n   - No logical deductions, simulations, or computations are required based on the provided information.\\n\\n4. EDUCATED GUESSES\\n   - None of the information provided allows for any educated guesses.\\n\\n\\nHere is the plan to follow as best as possible:\\n\\n- FileSurferAgent: Read the content of the local file \"c1.txt\".\\n- Summarize the content read from the file \"c1.txt\".\\n', type='TextMessage'), TextMessage(source='MagenticOneOrchestrator', models_usage=None, metadata={}, content='请读取本地文件 c1.txt 的内容并总结。', type='TextMessage'), TextMessage(source='FileSurferAgent', models_usage=None, metadata={}, content='Path: /home/userroot/dev/shallow_edu/course/docs/c1.txt\\nViewport position: Showing page 1 of 3.\\n=======================\\n提示词工程 (Prompt Engineering) 最佳实践\\nAI原生应用开发/实践案例\\n\\n免费大模型课程\\nLLM\\nPrompt\\n2024.06.26\\n28550看过\\n全面的专业 Prompt Engineering 入门宝典\\n复制\\n正文\\n\\nAI\\n智能创作\\n通用\\n图片\\n表格\\n附件\\n代码块\\n公式\\n超链接\\n提及\\n阅读统计\\n高亮信息\\n流程图\\n思维导图\\n文本格式\\n正文\\n一级标题\\n二级标题\\n三级标题\\n四级标题\\n五级标题\\n六级标题\\n无序列表\\n有序列表\\n待办列表\\n引用\\n分割线\\n数据表\\n表格视图\\n相册视图\\n看板视图\\n甘特视图\\n日历视图\\n架构视图\\n第三方应用\\nDuChat\\nBeta\\n百度地图\\nCodePen\\nFigma\\nPrompt Engineering 概念解析\\n提示工程是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型（Large Language Model, LLM）用于各场景和研究领域。研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。\\n例如，在openai官方提供的大模型中，text-davinci-003和davinci是最常用的两个模型。text-davinci-003是经过大量指令微(教)调(化)过的模型，而davinci则是Foundation模型没有经过“教化”。\\n对于经过教化的text-davinci-003模型，想要发挥其能力需要进行适当的prompt engineering来做引导。\\n而对于没有教化过的davinci模型，我们要把人为书写Prompt对其进行教化，即指令微调。虽然davinci模型本身通过Prompt Engineering可以激发其大量的底层能力，但通常由于准确度不够高而不具备实用性。\\n我们日常说的Prompt Engineering更是指如何激发一个被调教过的模型（举例，text-davinci-003、文心一言、chatglm等）所具备的成熟能力，更好的服务我们自己。\\n最简单的Prompt举例\\n备注：除非特别说明，本指南默认所有示例都是基于 OpenAI 的大语言模型 \\ufeff\\ufefftext-davinci-003\\ufeff\\ufeff 进行测试，并且使用该模型的默认配置，如 \\ufeff\\ufefftemperature=0.7\\ufeff\\ufeff 和 \\ufeff\\ufefftop_p=1\\ufeff\\ufeff 等。\\nTemperature：简单来说，\\ufeff\\ufefftemperature\\ufeff\\ufeff 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。我们目前也在增加其他可能 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 temperature 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，你可以适当调高 \\ufeff\\ufefftemperature\\ufeff\\ufeff 参数值。\\nTop_p：同样，使用 \\ufeff\\ufefftop_p\\ufeff\\ufeff（与 \\ufeff\\ufefftemperature\\ufeff\\ufeff 一起称为核采样的技术），可以用来控制模型返回结果的真实性。如果你需要准确和事实的答案，就把参数值调低。如果你想要更多样化的答案，就把参数值调高一些。\\n\\ufeff\\n需要Prompt Engineering 的场景\\n总结来说，需要进行Prompt Engineering的主要场景有如下两种：\\n对于不可被训练的GPT3.5+类的模型，想要获得更好的任务效果一般需要Prompt Engineering。其中，对于GPT3.5+类模型已有能力的探索相对简单，通过评估不同的Prompt效果即可。对于GPT3.5+类模型不太具备的能力，需要通过探索GPT3 Base模型能力的任务来说，还需要构造一些具备代表意义的Example，通过不断调整Prompt中的Task Description、Context、Examples来获得最优的效果，此场景下Prompt Engineering成本相对高。\\n对于可Instruction Tuning的模型来说，构造Prompt的成本相对较低，大部分成本转嫁给标注成本，通过在设计好的Prompt中调优任务的效果即可，不需要特殊的Prompt Enigineering。\\n\\ufeff\\n\\ufeff\\n\\n\\ufeff\\n注意：上图没有列出GPT3类模型需要进行Prompt Engineering的场景，原因是被GPT3.5进行Prompt Engineering的场景覆盖了。此外，在实际使用中，预置模型最好都是GPT3.5+类模型，具备一定优势能力后再进行实际应用。\\nPrompt Engineering 的方法\\nPrompt 的标准结构\\n整个Prompt可以看做是一个函数  模型输出 = F(用户输入)，而F本身就包括任务描述、上下文、示例等等，“Prompt Design工程师”主要的工作就是设计这个F。\\n\\ufeff\\n\\ufeff\\n\\n\\ufeff\\n示例\\nPrompt Engineering 的典型技术\\n零样本提示词\\n\\ufeff\\n少样本提示词\\n思维链提示法\\n零样本思维链提示法\\n设计全局性的System信息\\n\\ufeff\\n\\ufeff\\n\\n\\ufeff\\nPrompt Engineering 典型应用\\n生成数据\\n利用Prompt+真实数据，从InstructGPT模型中找到答案，作为训练数据或评估数据使用。举例子：从一篇文档中挖掘问答对、基于给定的实体生成相关的属性信息等。\\n构造副驾驶\\nPrompt Engineering 的效果检验\\n表述方式的评估：Prompt中的描述应该确保明确、准确、有结构性、简单易懂、不能有错别字和语法错误、不能有死链接\\n人工评估：对 Prompt + Completion 进行结果正确性的人工 review ，按照准确率来评估。\\n与 Text-Davinci-003 对比：通过对比 GSB 衡量与 GPT3.5 模型的效果对比。\\nPrompt质量评估自动化方法：计算人工设计的 Prompt 在 GPT3.5+ 模型上的 PPL (PPL, Perplexity, 即困惑度，是用来度量一个概率分布或概率模型预测样本的好坏程度的指标)。\\n可能的问题\\nPrompt越长性能越差：因为当前模型采用Transformer架构，计算复杂度有O(L^2)，L为文本序列token个数，因此Prompt越长性能越差。同时，Prompt越长，模型单次解码可生成的文本长度越短。解决方案：如果Prompt过长导致预测性能不符合预期，采用instruction tuning在效果和成本方面都更有优势。\\n缩短Prompt的进阶方法：对于一些Prompt，例如阅读理解任务，需要在Prompt中加入外部的文本形成完成的Prompt，这种情形下通常难以缩短Prompt。一种可行的方法是把外部文本当成预训练文本语料学习到模型里，让模型记忆其中的一部分知识，再通过Prompt设计直接进行context-free的问答。\\n对于确定场景：用户需要输入较多Prompt描述才能正确获得结果，使用体验会明显下降。解决方案：尽量开放以【用户输入】为参数的API直接给用户使用，而不是输入整个Prompt，将Prompt固化到API中，可以保持效果稳定和更新的灵活性。\\nPrompt 题库与示例\\n根据BIG-BENCH对任务类别梳理，挑选四大类任务重点关注，分别是自然语言理解、科学知识、世界知识（通识）、职业角色扮演\\n理解类\\n学科知识\\n世界知识（通识）\\n职业角色扮演\\n\\ufeff\\n编号\\n任务\\nPrompt示例\\n1\\n语言检测器\\n我希望你充当语言检测器。我会用任何语言输入一个句子，你会回答我，我写的句子在你是用哪种语言写的。不要写任何解释或其他文字，只需回复语言名称即可。我的第一句话是“Kiel vi fartas？Kiel iras via tago？”\\n2\\n充当英语翻译和改进者\\n我想让你充当英语翻译员、拼写纠正员和改进员。我会用任何语言与你交谈，你会检测语言，翻译它并用我的文本的更正和改进版本用英语回答。我希望你用更优美优雅的高级英语单词和句子替换我简化的 A0 级单词和句子。保持相同的意思，但使它们更文艺。我要你只回复更正、改进，不要写任何解释。我的第一句话是“istanbulu cok seviyom burada olmak cok guzel”\\n3\\n充当英英词典(附中文解释)\\n我想让你充当英英词典，对于给出的英文单词，你要给出其中文意思以及英文解释，并且给出一个例句，此外不要有其他反馈，第一个单词是“Hello\"\\n4\\n担任面试官\\n我想让你担任Android开发工程师面试官。我将成为候选人，您将向我询问Android开发工程师职位的面试问题。我希望你只作为面试官回答。不要一次写出所有的问题。我希望你只对我进行采访。问我问题，等待我的回答。不要写解释。像面试官一样一个一个问我，等我回答。我的第一句话是“面试官你好”\\n5\\n充当旅游指南\\n我想让你做一个旅游指南。我会把我的位置写给你，你会推荐一个靠近我的位置的地方。在某些情况下，我还会告诉您我将访问的地方类型。您还会向我推荐靠近我的第一个位置的类似类型的地方。我的第一个建议请求是“我在上海，我只想参观博物馆。”\\n6\\n充当抄袭检查员\\n我想让你充当剽窃检查员。我会给你写句子，你只会用给定句子的语言在抄袭检查中未被发现的情况下回复，别无其他。不要在回复上写解释。我的第一句话是“为了让计算机像人类一样行动，语音识别系统必须能够处理非语言信息，例如说话者的情绪状态。”\\n7\\n充当“电影/书籍/任何东西”中的“角色”\\n我希望你表现得像{series} 中的{Character}。我希望你像{Character}一样回应和回答。不要写任何解释。只回答像{character}。你必须知道{character}的所有知识。我的第一句话是“你好”\\n8\\n作为广告商\\n我想让你充当广告商。您将创建一个活动来推广您选择的产品或服务。您将选择目标受众，制定关键信息和口号，选择宣传媒体渠道，并决定实现目标所需的任何其他活动。我的第一个建议请求是“我需要帮助针对 18-30 岁的年轻人制作一种新型能量饮料的广告活动。”\\n9\\n充当讲故事的人\\n我想让你扮演讲故事的角色。您将想出引人入胜、富有想象力和吸引观众的有趣故事。它可以是童话故事、教育故事或任何其他类型的故事，有可能吸引人们的注意力和想象力。根据目标受众，您可以为讲故事环节选择特定的主题或主题，例如，如果是儿童，则可以谈论动物；如果是成年人，那么基于历史的故事可能会更好地吸引他们等等。我的第一个要求是“我需要一个关于毅力的有趣故事。”\\n10\\n担任足球解说员\\n我想让你担任足球评论员。我会给你描述正在进行的足球比赛，你会评论比赛，分析到目前为止发生的事情，并预测比赛可能会如何结束。您应该了解足球术语、战术、每场比赛涉及的球员/球队，并主要专注于提供明智的评论，而不仅仅是逐场叙述。我的第一个请求是“我正在观看曼联对切尔西的比赛——为这场比赛提供评论。”\\n11\\n扮演脱口秀喜剧演员\\n我想让你扮演一个脱口秀喜剧演员。我将为您提供一些与时事相关的话题，您将运用您的智慧、创造力和观察能力，根据这些话题创建一个例程。您还应该确保将个人轶事或经历融入日常活动中，以使其对观众更具相关性和吸引力。我的第一个请求是“我想要幽默地看待政治”。\\n12\\n充当励志教练\\n我希望你充当激励教练。我将为您提供一些关于某人的目标和挑战的信息，而您的工作就是想出可以帮助此人实现目标的策略。这可能涉及提供积极的肯定、提供有用的建议或建议他们可以采取哪些行动来实现最终目标。我的第一个请求是“我需要帮助来激励自己在为即将到来的考试学习时保持纪律”。\\n13\\n担任辩手\\n我要你扮演辩手。我会为你提供一些与时事相关的话题，你的任务是研究辩论的双方，为每一方提出有效的论据，驳斥对立的观点，并根据证据得出有说服力的结论。你的目标是帮助人们从讨论中解脱出来，增加对手头主题的知识和洞察力。我的第一个请求是“我想要一篇关于 Deno 的评论文章。”\\n14\\n担任职业顾问\\n我想让你担任职业顾问。我将为您提供一个在职业生涯中寻求指导的人，您的任务是帮助他们根据自己的技能、兴趣和经验确定最适合的职业。您还应该对可用的各种选项进行研究，解释不同行业的就业市场趋势，并就哪些资格对追求特定领域有益提出建议。我的第一个请求是“我想建议那些想在软件工程领域从事潜在职业的人。”\\n', type='TextMessage'), TextMessage(source='MagenticOneOrchestrator', models_usage=None, metadata={}, content='根据文件 \"c1.txt\" 的内容，这是一篇关于提示词工程（Prompt Engineering）最佳实践的总结。文章首先介绍了提示词工程的概念及其在提升大语言模型处理复杂任务场景能力中的作用，特别是对于经过微调的如 text-davinci-003 模型而言。它还详细讨论了需要进行提示词工程的主要场景、方法以及典型应用。这些应用包括生成数据、构造副驾驶、增强表述方式等，并列举了一些具体的Prompt示例来帮助理解如何在实际任务中使用提示词工程。\\n\\n总结来看，提示词工程是通过精心设计和优化提示词来充分利用大语言模型的能力的一种技术。它对于提升特定任务的效果至关重要，并且适用于多种场景，从简单的零样本或少样本提示词到复杂的对话模拟等。', type='TextMessage')], stop_reason='文件已读取并总结。')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email.mime import base\n",
    "import os\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_ext.agents.file_surfer import FileSurfer  # 导入正确的FileSurferAgent类\n",
    "\n",
    "# 创建 FileSurfer 代理\n",
    "file_surfer = FileSurfer(\n",
    "    name=\"FileSurferAgent\",\n",
    "    model_client=ollama_client,\n",
    "    base_path=os.path.expanduser(\"~/dev/shallow_edu/course/docs\"),\n",
    ")\n",
    "\n",
    "# 定义终止条件\n",
    "termination_condition = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# 创建 MagenticOneGroupChat 团队\n",
    "team = MagenticOneGroupChat([file_surfer], model_client=ollama_client, termination_condition=termination_condition)\n",
    "\n",
    "# 定义任务，例如读取本地文件\n",
    "task = \"读取本地文件 c1.txt 的内容并总结。\"\n",
    "\n",
    "# 运行任务\n",
    "await Console(team.run_stream(task=task))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52302cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ollama_client.create([UserMessage(content=\"中国首都是?\", source=\"user\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f404f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.conditions import ExternalTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = ollama_client\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that stops the task if the critic approves.\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create a team with the primary and critic agents.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset()  # Reset the team for a new task.\n",
    "await Console(team.run_stream(task=\"写一首五言绝句，关于夏天的热\"))  # Stream the messages to the console.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20df238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "\n",
    "\n",
    "# 创建文件读取 Agent\n",
    "file_reader_agent = AssistantAgent(\n",
    "    name=\"FileReaderAgent\",\n",
    "    model_client=ollama_client,\n",
    "    description=\"An agent that can read and process local text files.\",\n",
    "    system_message=\"\"\"You are an agent capable of reading local text files. \n",
    "    When asked to read a file, use the provided file path and return its contents.\n",
    "    If the file doesn't exist or there's an error, report it clearly.\"\"\"\n",
    ")\n",
    "\n",
    "# 创建用户代理\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    #model_client=ollama_client,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"docs\",\n",
    "        \"use_docker\": False  # 设置为 False 以在本地运行\n",
    "    }\n",
    ")\n",
    "\n",
    "# 定义读取文件的函数\n",
    "def read_local_file(file_path: str) -> str:\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return f\"Error: File '{file_path}' does not exist.\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file '{file_path}': {str(e)}\"\n",
    "\n",
    "# 注册文件读取功能到 agent\n",
    "file_reader_agent.register_function(\n",
    "    function_map={\n",
    "        \"read_local_file\": read_local_file\n",
    "    }\n",
    ")\n",
    "\n",
    "# 在 Notebook 中运行异步代码\n",
    "async def main():\n",
    "    file_path = \"test.txt\"\n",
    "    result = await user_proxy.initiate_chat(\n",
    "        recipient=file_reader_agent,\n",
    "        message=f\"Please read the content of the file: {file_path}\"\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "# 执行异步任务\n",
    "result = await main()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
